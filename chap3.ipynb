{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc5e131a",
   "metadata": {},
   "source": [
    "**Chapter 3 - Linear Regression**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49660ab2",
   "metadata": {},
   "source": [
    "Regression is the act of fitting a model to a dataset. We try to fit the model as closely to our data as possible. Close can be considered in different ways, however, generally we can try to optimize for the least squares. \n",
    "\n",
    "On averages, we want the smallest Residual Sum of Squares. Sum of squares between the predicted values and the Y true values: \n",
    "* $RSS = \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2$\n",
    "\n",
    "So in our regression we need to pick betas in $y = \\beta_0 + \\beta_1 x + \\epsilon$ which minimize the RSS. \n",
    "\n",
    "Our intercept term represent the value of Y if all other Xs are 0. \n",
    "\n",
    "*Law of Law Numbers* - As we take increasing samples, the sample statistic will begin to resemble the population statistic. \n",
    "*Central Limit Theorum* - As we continue taking sample means, the sampled means will begin to follow a normal distribution. \n",
    "\n",
    "When we fit a regression model, we have no guarantee that our coefficients will actually be the true coeffcients. However, if we conduct many regressions with multiple datasets and average the coefficients we can likely get close to the true coefficient values. \n",
    "\n",
    "The Standard Error tells how far away our sample mean is likely away from the true population mean. SE is simply the sample standard deviation divided by the square root of N. Intuitively the more N or samples we have the less standard error we'll have. More sample greater likelihood our sample mean is representative of the poplation mean. \n",
    "\n",
    "Similarly, we can compute the SE of our coefficient as well to gain a sense of whether or not they're representative of the population coefficient. \n",
    "* $SE(\\hat{\\beta}_1) = \\sqrt{\\frac{MSE}{\\sum(x_i - \\bar{x})^2}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "500d3f7f",
   "metadata": {},
   "source": [
    "Standard Errors will also help us calculate confidence intervals. Confidence Intervals are ways of expressing a statistic with a margin of error. \n",
    "Confidence Interval = Significant Level * Standard Error\n",
    "Sig Level is determined by the confidence we want to have for 95 percent, 1.96\n",
    "Standard Error is the Population Standard Deviation / sqrt of N. \n",
    "Then 95% of the time the statistic should be represented without our window. \n",
    "\n",
    "*How to frame the utility of Confidence Intervals for regression?*\n",
    "* If we determine that for Beta1 which is advertising budget and our Y is total sales. If we estimate a confidence intevals for Beta1 of [5,10] then we could say that 1 extra dollar of advertising should lead to between 5 and 10 extra dollars in sales. \n",
    "\n",
    "*Purpose of coefficient values for Hypothesis testing?*\n",
    "* If we want to test whether or not some variable Beta1 has an influence on the outcome variable we could say that if Beta1 is 0 then the model is telling us there is no relationship. So how big of a coefficient would we need to determine that there is a relationship? One thing to consider is the standard error of the coefficient. A large standard error would suggest that we need a larger coefficient to be sure there is a relationship. A smaller SE would mean smaller coefficients are ok to show relationships. We can calulate the t-statistic, \n",
    "    * T = ( Beta1 - 0 ) / Standard Error\n",
    "The t statistic tells us how many standard deviations away the statistic is from the mean. Using the T statistic, we can then compute the Pvalue. \n",
    "The Pvalue tell us that given the H0 or null hypothesis is true. What are the chances that we would see data like this? If the pvalue is under 0.05 we reject as is seems Beta 1 does have an impact. \n",
    "\n",
    "* Type 1 Error = Alpha  = False Positive \n",
    "    * The risk we're willing to take of a false postive. Or in other words, rejective the null hypothesis when we shouldnt have. \n",
    "* Typer 2 Error = Beta = False Negative  \n",
    "    * Typically used to help determine power which is 1- beta, and we typically go for ROT 80% desired power. This means chances of a false negative are 20? \n",
    "\n",
    "Remember power is a signal of how strong your test is. More specifically, it is the likelihood of if there is a positive effect, what are the odds that your test will be able to detect such. Power is a function of\n",
    "    * Sample Size - the larger the sample size the greater our power, intuitive\n",
    "    * Effect Size - how large of an impact we're trying to see \n",
    "    * Significant Level - typically 0.05\n",
    "    * Population or sample variance - greater variance will reduce power\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "680241e5",
   "metadata": {},
   "source": [
    "**Assessing the extent to which the model fits the data**\n",
    "\n",
    "Once we have determined which coefficients indeed have an impact on the Y outcome variable we want to quantify how well our model actually does. MSE can tell us something, but its not an intuitive metric to see how well does our model actually model Y? \n",
    "\n",
    "We can look at two unrelated quantities: \n",
    "* RSE - Residual Standard Error \n",
    "    * Even if we had perfect coefficients we still wouldnt be able to perfectly model Y.\n",
    "    * Essentially the standard deviation of our errors. It is known as a measure of the lack of fit. \n",
    "    * Expressed in actual terms of Y. \n",
    "    * So the output number here and whether or not the RSE is exceptable depends on the context of the problem. \n",
    "* $R^2$ \n",
    "    * How much of the variance of Y is our model able to explain. \n",
    "    * Unlike RSE which is expressed in unit of Y, the $R^2$  is able to provide a number between 0-1. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a0fec0",
   "metadata": {},
   "source": [
    "**Multiple Linear Regression**\n",
    "\n",
    "In the real world we likely have access to multiple predictors we could use to model Y. Instead of running n simple linear regressions we can run multiple linear regression to capture all of these predictors. This has several benefits over using multiple simple linear regression, as when we just have one predictor the coefficient ignore the influence of the other predictors on the outcome variable Y. The simpsons paradox also describes that some variables and their relationship with Y might become completely diminished after introducing other variables. We're also able to still model the influence of one coefficient while keeping others constant. \n",
    "\n",
    "To find the optimal coefficients, we select them using least squares or the coefficients that minimize the Square Sum of Residuals. \n",
    "\n",
    "The benefit is also that by introducing more predictors we can eliminate some of the chances of confounding variables. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "692184ae",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
